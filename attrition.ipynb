{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alIIEHibGc3M"
   },
   "source": [
    "## Part 1: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "6eDUJ4NtGc3P",
    "outputId": "2480098c-135c-4cbf-9552-018494ee8ff5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 06:35:41.358774: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>...</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel              Department  DistanceFromHome  \\\n",
       "0   41       Yes      Travel_Rarely                   Sales                 1   \n",
       "1   49        No  Travel_Frequently  Research & Development                 8   \n",
       "2   37       Yes      Travel_Rarely  Research & Development                 2   \n",
       "3   33        No  Travel_Frequently  Research & Development                 3   \n",
       "4   27        No      Travel_Rarely  Research & Development                 2   \n",
       "\n",
       "   Education EducationField  EnvironmentSatisfaction  HourlyRate  \\\n",
       "0          2  Life Sciences                        2          94   \n",
       "1          1  Life Sciences                        3          61   \n",
       "2          2          Other                        4          92   \n",
       "3          4  Life Sciences                        4          56   \n",
       "4          1        Medical                        1          40   \n",
       "\n",
       "   JobInvolvement  ...  PerformanceRating RelationshipSatisfaction  \\\n",
       "0               3  ...                  3                        1   \n",
       "1               2  ...                  4                        4   \n",
       "2               2  ...                  3                        2   \n",
       "3               3  ...                  3                        3   \n",
       "4               3  ...                  3                        4   \n",
       "\n",
       "   StockOptionLevel TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \\\n",
       "0                 0                 8                      0               1   \n",
       "1                 1                10                      3               3   \n",
       "2                 0                 7                      3               3   \n",
       "3                 0                 8                      3               3   \n",
       "4                 1                 6                      3               3   \n",
       "\n",
       "   YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0               6                   4                        0   \n",
       "1              10                   7                        1   \n",
       "2               0                   0                        0   \n",
       "3               8                   7                        3   \n",
       "4               2                   2                        2   \n",
       "\n",
       "   YearsWithCurrManager  \n",
       "0                     5  \n",
       "1                     7  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     2  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#  Import and read the attrition data\n",
    "attrition_df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m19/lms/datasets/attrition.csv')\n",
    "attrition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g22aQSY4Gc3Q",
    "outputId": "1f5c13c1-b981-4e40-a7ed-dd3fe6f1b81e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         43\n",
       "Attrition                    2\n",
       "BusinessTravel               3\n",
       "Department                   3\n",
       "DistanceFromHome            29\n",
       "Education                    5\n",
       "EducationField               6\n",
       "EnvironmentSatisfaction      4\n",
       "HourlyRate                  71\n",
       "JobInvolvement               4\n",
       "JobLevel                     5\n",
       "JobRole                      9\n",
       "JobSatisfaction              4\n",
       "MaritalStatus                3\n",
       "NumCompaniesWorked          10\n",
       "OverTime                     2\n",
       "PercentSalaryHike           15\n",
       "PerformanceRating            2\n",
       "RelationshipSatisfaction     4\n",
       "StockOptionLevel             4\n",
       "TotalWorkingYears           40\n",
       "TrainingTimesLastYear        7\n",
       "WorkLifeBalance              4\n",
       "YearsAtCompany              37\n",
       "YearsInCurrentRole          19\n",
       "YearsSinceLastPromotion     16\n",
       "YearsWithCurrManager        18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "attrition_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "50vMgBEnJbfM"
   },
   "outputs": [],
   "source": [
    "# Create y_df with the Attrition and Department columns\n",
    "y_df = attrition_df[['Attrition', 'Department']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Virka0zLGc3R",
    "outputId": "dd5aee3a-9458-4ba6-e857-1b234de40915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                         int64\n",
      "DistanceFromHome            int64\n",
      "JobSatisfaction             int64\n",
      "OverTime                   object\n",
      "StockOptionLevel            int64\n",
      "WorkLifeBalance             int64\n",
      "YearsAtCompany              int64\n",
      "YearsSinceLastPromotion     int64\n",
      "NumCompaniesWorked          int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a list of at least 10 column names to use as X data\n",
    "X_col = ['Age','DistanceFromHome','JobSatisfaction','OverTime','StockOptionLevel','WorkLifeBalance','YearsAtCompany','YearsSinceLastPromotion','NumCompaniesWorked']\n",
    "\n",
    "# Create X_df using your selected columns\n",
    "X_df = attrition_df[X_col]\n",
    "\n",
    "# Show the data types for X_df\n",
    "#X_df.info()\n",
    "print(X_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KaJfdOGUMHMR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1176, 9), X_test shape: (294, 9)\n",
      "y_train shape: (1176, 2), y_test shape: (294, 2)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, random_state=13, test_size=0.2)\n",
    "\n",
    "# Verify the split sizes\n",
    "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Types After Conversion:\n",
      "Age                          int64\n",
      "DistanceFromHome             int64\n",
      "JobSatisfaction              int64\n",
      "OverTime                   float64\n",
      "StockOptionLevel             int64\n",
      "WorkLifeBalance              int64\n",
      "YearsAtCompany               int64\n",
      "YearsSinceLastPromotion      int64\n",
      "NumCompaniesWorked           int64\n",
      "dtype: object\n",
      "\n",
      "Missing Values After Conversion:\n",
      "Age                           0\n",
      "DistanceFromHome              0\n",
      "JobSatisfaction               0\n",
      "OverTime                   1470\n",
      "StockOptionLevel              0\n",
      "WorkLifeBalance               0\n",
      "YearsAtCompany                0\n",
      "YearsSinceLastPromotion       0\n",
      "NumCompaniesWorked            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical columns to numeric\n",
    "#for col in X_df.columns:\n",
    "   # if X_df[col].dtype == 'object':  # If column is categorical\n",
    "        # If the column has only two unique values, map them to 0 and 1\n",
    "        #if X_df[col].nunique() == 2:\n",
    "            #X_df[col] = X_df[col].map({X_df[col].unique()[0]: 0, X_df[col].unique()[1]: 1})\n",
    "        #else:\n",
    "            # For columns with more than two unique values, apply one-hot encoding\n",
    "            #X_df = pd.get_dummies(X_df, columns=[col], drop_first=True)\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "#X_df = X_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Check the data types after conversion\n",
    "#print(\"\\nData Types After Conversion:\")\n",
    "#print(X_df.dtypes)\n",
    "\n",
    "# Verify if there are any missing values created during conversion\n",
    "#print(\"\\nMissing Values After Conversion:\")\n",
    "#print(X_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Age                      1470 non-null   float32\n",
      " 1   DistanceFromHome         1470 non-null   float32\n",
      " 2   JobSatisfaction          1470 non-null   float32\n",
      " 3   OverTime                 0 non-null      float32\n",
      " 4   StockOptionLevel         1470 non-null   float32\n",
      " 5   WorkLifeBalance          1470 non-null   float32\n",
      " 6   YearsAtCompany           1470 non-null   float32\n",
      " 7   YearsSinceLastPromotion  1470 non-null   float32\n",
      " 8   NumCompaniesWorked       1470 non-null   float32\n",
      "dtypes: float32(9)\n",
      "memory usage: 51.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Converting features from integer to float\n",
    "X_df = X_df.astype('float32')\n",
    "\n",
    "# Check data types\n",
    "X_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYubUJqiLCSp",
    "outputId": "53f31721-571c-4c94-d13e-25a715749593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OverTime conversion to numeric completed.\n",
      "Number of employees with OverTime: 0\n",
      "Number of employees without OverTime: 0\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: OverTime, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1v/7fmxq0990t15jzs3_4660r680000gn/T/ipykernel_5659/3592356281.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_df['OverTime'] = X_df['OverTime'].map({'Yes': 1, 'No': 0})\n"
     ]
    }
   ],
   "source": [
    "# Convert your X data to numeric data types however you see fit\n",
    "# Add new code cells as necessary \n",
    "X_df['OverTime'] = X_df['OverTime'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "#No     788\n",
    "#Yes    314\n",
    "#Name: OverTime, dtype: int64\n",
    "# Count the number of employees with and without OverTime\n",
    "overtime_counts = X_df['OverTime'].value_counts()\n",
    "\n",
    "# Display the results\n",
    "#overtime_counts.()\n",
    "# Display the results\n",
    "print(\"OverTime conversion to numeric completed.\")\n",
    "print(f\"Number of employees with OverTime: {overtime_counts.get(1, 0)}\")\n",
    "print(f\"Number of employees without OverTime: {overtime_counts.get(0, 0)}\")\n",
    "print(X_df['OverTime'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EWA-aIA5Gc3T"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'No'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1v/7fmxq0990t15jzs3_4660r680000gn/T/ipykernel_5659/612011304.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a StandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Fit the StandardScaler to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Scale the training and testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m         \"\"\"\n\u001b[1;32m    876\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \"\"\"\n\u001b[1;32m    913\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1009\u001b[0m                         )\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n\u001b[1;32m   1015\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'No'"
     ]
    }
   ],
   "source": [
    "# Create a StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit the StandardScaler to the training data\n",
    "scaler.fit(X_train)\n",
    "# Scale the training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Verify the shapes of the scaled datasets\n",
    "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
    "print(f\"X_test_scaled shape: {X_test_scaled.shape}\")                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-z0Mky8vQSz4",
    "outputId": "debefc85-c20b-48f5-f4d9-91eadd65d36a"
   },
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder for the Department column\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "dept_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit the encoder to the training data\n",
    "dept_y_train = y_train['Department']\n",
    "dept_y_test = y_test['Department']\n",
    "\n",
    "# Create two new variables by applying the encoder\n",
    "# to the training and testing data\n",
    "dept_y_train  = dept_encoder.fit_transform(np.array(dept_y_train).reshape(-1,1))\n",
    "dept_y_test = dept_encoder.fit_transform(np.array(dept_y_test).reshape(-1,1))\n",
    "\n",
    "dept_y_train\n",
    "\n",
    "#array([[0., 1., 0.],\n",
    "#[0., 1., 0.],\n",
    "       #[0., 1., 0.],\n",
    "      # ...,\n",
    "       #[0., 1., 0.],\n",
    "       #[0., 0., 1.],\n",
    "       #[0., 1., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder for the Department column\n",
    "dept_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit the encoder to the training data and transform both datasets\n",
    "dept_y_train = dept_encoder.fit_transform(y_train[['Department']])\n",
    "dept_y_test = dept_encoder.transform(y_test[['Department']])\n",
    "\n",
    "# Display the transformed data for verification\n",
    "#print(f\"Department Training Data Shape: {dept_y_train.shape}\")\n",
    "#print(f\"Department Testing Data Shape: {dept_y_test.shape}\")\n",
    "dept_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-G4DSpvFRrk4",
    "outputId": "9842e948-8a55-4b80-8fac-f96714e85589"
   },
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder for the Attrition column\n",
    "attrit_encoder = OneHotEncoder(sparse_output=False)\n",
    "attrition_y_train = y_train['Attrition']\n",
    "attrition_y_test = y_test['Attrition']\n",
    "# Fit the encoder to the training data\n",
    "attrition_y_train = attrit_encoder.fit_transform(np.array(y_train[['Attrition']]))\n",
    "attrition_y_test = attrit_encoder.fit_transform(np.array(y_test[['Attrition']]))\n",
    "# Create two new variables by applying the encoder\n",
    "# to the training and testing data\n",
    "\n",
    "attrition_y_train\n",
    "\n",
    "#array([[1., 0.],\n",
    "#[0., 1.],\n",
    "      #[1., 0.],\n",
    "#...,\n",
    "       #[1., 0.],\n",
    "       #[1., 0.],\n",
    "       #[1., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder for the Attrition column\n",
    "attrit_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit the encoder to the training data and transform both datasets\n",
    "attrition_y_train = attrit_encoder.fit_transform(y_train[['Attrition']])\n",
    "attrition_y_test = attrit_encoder.transform(y_test[['Attrition']])\n",
    "\n",
    "# Display the transformed data for verification\n",
    "#print(f\"Attrition Training Data Shape: {attrition_y_train.shape}\")\n",
    "#print(f\"Attrition Testing Data Shape: {attrition_y_test.shape}\")\n",
    "attrition_y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykNmu_WWGc3T"
   },
   "source": [
    "## Create, Compile, and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUptZqmSGc3T"
   },
   "outputs": [],
   "source": [
    "# Find the number of columns in the X training data\n",
    "features = X_train_scaled.shape[1]\n",
    "\n",
    "# Create the input layer\n",
    "input_layer = layers.Input(shape=(features,), name='input_layer')\n",
    "\n",
    "# Create at least two shared layers\n",
    "shared_layer1 = layers.Dense(64, activation='relu')(input_layer)\n",
    "shared_layer2 = layers.Dense(32, activation='relu')(shared_layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JukjTm2yTEqd"
   },
   "outputs": [],
   "source": [
    "# Create a branch for Department\n",
    "# with a hidden layer and an output layer\n",
    "\n",
    "# Create the hidden layer\n",
    "dept_hidden = layers.Dense(16, activation='relu')(shared_layer2)\n",
    "\n",
    "# Create the output layer\n",
    "dept_output = layers.Dense(dept_y_train.shape[1], activation='softmax', name=\"Department_Output\")(dept_hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OqhUiOJUBkR"
   },
   "outputs": [],
   "source": [
    "# Create a branch for Attrition\n",
    "# with a hidden layer and an output layer\n",
    "\n",
    "# Create the hidden layer\n",
    "attr_hidden = layers.Dense(16, activation='relu')(shared_layer2)\n",
    "\n",
    "# Create the output layer\n",
    "attr_output = layers.Dense(1, activation='sigmoid', name=\"Attrition_Output\")(attr_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twmuejdxGc3T",
    "outputId": "25096308-b68b-42e4-e4ea-ae82e97c435a"
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=[dept_output, attr_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'Department_Output': 'categorical_crossentropy', 'Attrition_Output': 'binary_crossentropy'},\n",
    "    metrics={'Department_Output': 'accuracy', 'Attrition_Output': 'accuracy'}\n",
    ")\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8oGy0dpGc3U",
    "outputId": "cc667d43-28cf-42d4-d719-c2bc02888d30"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    {'Department_Output': dept_y_train, 'Attrition_Output': attrition_y_train},\n",
    "    validation_data=(X_test_scaled, {'Department_Output': dept_y_test, 'Attrition_Output': attrition_y_test}),\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsMoaQlgGc3U",
    "outputId": "1bd4e601-e964-4abc-ad83-aeecf6b696be"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model with the testing data\n",
    "evaluation = model.evaluate(X_test_scaled, {'Department_Output': dept_y_test, 'Attrition_Output': attrition_y_test})\n",
    "# Display evaluation results\n",
    "print(f\"Evaluation Results: {evaluation}\")\n",
    "#[4.162380218505859,\n",
    " #3.114327907562256,\n",
    " #1.0480519533157349,\n",
    " #0.5271739363670349,\n",
    " #0.8260869383811951]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlCtlHi0Vt54",
    "outputId": "bc21ef3e-80c2-4b38-9c29-79515bc23dec"
   },
   "outputs": [],
   "source": [
    "# Print the accuracy for both department and attrition\n",
    "print(f\"Attrition Accuracy: {evaluation[3]}\")   \n",
    "print(f\"Department Accuracy: {evaluation[4]}\")  \n",
    "\n",
    "#Department predictions accuracy: 0.5271739363670349\n",
    "#Attrition predictions accuracy: 0.8260869383811951"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGSyfsZfWOQM"
   },
   "source": [
    "# Summary\n",
    "\n",
    "In the provided space below, briefly answer the following questions.\n",
    "\n",
    "1. Is accuracy the best metric to use on this data? Why or why not?\n",
    "\n",
    "2. What activation functions did you choose for your output layers, and why?\n",
    "\n",
    "3. Can you name a few ways that this model might be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pi9SLpFnWvbF"
   },
   "source": [
    "YOUR ANSWERS HERE\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
